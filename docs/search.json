[
  {
    "objectID": "papers/final/x-community-notes-effectiveness.html",
    "href": "papers/final/x-community-notes-effectiveness.html",
    "title": "Effectiveness and Systematic Constraints of Community Notes",
    "section": "",
    "text": "Code\n## import libraries\nlibrary(conflicted)\nlibrary(corrr)\nlibrary(mice, warn.conflicts = FALSE)\nlibrary(patchwork)\nlibrary(quantreg)\nlibrary(ranger)\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n# prefs\nconflict_prefer('filter','dplyr')\nconflict_prefer('select','dplyr')\nset.seed(40)\n\n# ggplot\ncustom_theme &lt;- theme_minimal() + theme(plot.title = element_text(size = 12))\ntheme_set(custom_theme)\n\n## Data load\n\n# csv\ndf_notes &lt;- read_csv('data/df_notes.csv')\ndf_tweets_sum &lt;- read_csv('data/df_tweets_sum.csv')\ndf_nicenames &lt;- read_csv('data/nicenames.csv')\n\n# db\n# library(duckdb)\n# con &lt;- dbConnect(duckdb(), dbdir='/Volumes/seagate_5tb/twitter.duckdb', read_only=TRUE)\n# df_notes &lt;- dbGetQuery(con, \"select * from analysis.notes_ttp\")\n# df_tweets_sum &lt;- dbGetQuery(con, \"select * from analysis.tweets_all_summary\")\n# df_tweets_noted_sum &lt;- dbGetQuery(con, \"select * from analysis.tweets_noted_summary\")\n# dbDisconnect(con, shutdown = TRUE)\n\n# save these to file for final paper\n# write.csv(df_notes, 'data/df_notes.csv', row.names=FALSE)\n# write.csv(df_tweets_sum, 'data/df_tweets_sum.csv', row.names=FALSE)\n\n## Data prep for EDA\n\n# initial feature select - unused features\ndrop_cols = c('nt_id','nt_summary','nt_author_id','nt_ts_created','twt_id','twt_author_id','twt_reply_author_id','twt_convo_id','twt_url','user_created_dt','nt_class_notmis_notoutdated','twt_is_retweet','nr_helpful_empathy','nr_helpful_ctxt_unique','nr_nothelpful_opinion_bias','nr_nothelpful_outdated','nr_nothelpful_offtopic','nt_created_min')\n\ndf_notes_all &lt;- df_notes %&gt;% select(-all_of(drop_cols)) \ndf_notes_pub &lt;- df_notes %&gt;% filter(nt_publish == 1) %&gt;% select(-all_of(drop_cols)) %&gt;% select(-all_of('nt_publish'))\ndf_notes_unpub &lt;- df_notes %&gt;% filter(nt_publish == 0) %&gt;% select(-all_of(drop_cols)) %&gt;% select(-all_of('nt_publish'))"
  },
  {
    "objectID": "papers/final/x-community-notes-effectiveness.html#x-community-notes",
    "href": "papers/final/x-community-notes-effectiveness.html#x-community-notes",
    "title": "Effectiveness and Systematic Constraints of Community Notes",
    "section": "4.1 X Community Notes",
    "text": "4.1 X Community Notes\n\nProgram Background\nCommunity-Driven Interventions, or CDIs, represent a shift from centralized platform moderation to crowd-sourced approaches.\nX Community Notes launched in 2021 as “Birdwatch” and combines user-generated fact checking with complex algorithmic approaches to publish only those Notes that achieve a broad consensus between approved program participants.\n\nApproved program participants create Community Notes on posts they believe contain misleading information, adding context and classifying content as potentially misleading or not, with their reasoning and sources.\nOther program participants (who must have a sufficient “rating impact” score) then rate these Community Notes as Helpful/Not Helpful based on whether they provide valuable context.\nX’s algorithms use these ratings to calculate an overall “helpfulness score” for each Community Note, identifying those that earn consensus across users with diverse rating histories (e.g., “people who normally disagree found this Note helpful”).\nOnly Community Notes that reach a sufficient helpfulness threshold from opinion-diverse raters are publicly displayed on posts.\nThe presence of a Community Note on a given post does not restrict the post from public view or interfere with any of the engagement tools (likes, reposts, etc.)"
  },
  {
    "objectID": "papers/final/x-community-notes-effectiveness.html#x-posts-tweets",
    "href": "papers/final/x-community-notes-effectiveness.html#x-posts-tweets",
    "title": "Effectiveness and Systematic Constraints of Community Notes",
    "section": "5.1 X Posts (Tweets)",
    "text": "5.1 X Posts (Tweets)\nThe 2024 Election Integrity Initiative at USC publishes a curated, publicly available dataset of X posts (tweets) related to the 2024 US Presidential Election. (Balasubramanian et al., n.d.)\nThis dataset was retrieved on March 1, 2025, and converted from CSV to Parquet. Dataset was then loaded into a persistent database using DuckDB, reducing total storage size from 45GB to 27GB and enabling reasonable database performance on consumer hardware.\nAvailable fields include original post ID, author ID and account details, replied-to or mentioned author IDs, text content, hashtags, links to media content, views and other engagement metrics. See Appendix 9.1 for a data dictionary of the composite table analysis.notes_ttp."
  },
  {
    "objectID": "papers/final/x-community-notes-effectiveness.html#x-community-notes-1",
    "href": "papers/final/x-community-notes-effectiveness.html#x-community-notes-1",
    "title": "Effectiveness and Systematic Constraints of Community Notes",
    "section": "5.2 X Community Notes",
    "text": "5.2 X Community Notes\nX maintains a public repository of Community Notes data featuring annotated user-generated Notes with timestamps, contributor metadata, community ratings and algorithmically determined publishing status. (“X Community Notes” 2025)\nAll four Community Notes datasets (Notes, Ratings, Note Status History and User Enrollment) were retrieved on February 22, 2025, and converted from CSV to Parquet. Datasets were then loaded into a persistent database using DuckDB, reducing total storage size from 30GB to 4GB (high sparsity) and enabling reasonable database performance on consumer hardware.\nTwo main sets of Community Note metrics were analyzed for this study, Post Classifications and Note Ratings. See Appendix 9.1 for a data dictionary of the composite table analysis.notes_ttp.\n\nPost Classifications\nDesignated by the Community Note author, classifying whether the attached Post is misinformation / misleading, with subcategories for additional context. These are expressed as Boolean in the dataset.\n\n\n\n\n\n\n\nPost is Not Misinfo\n(nt_class_misinfo = 0)\nPost is Misinfo\n(nt_class_misinfo = 1)\n\n\n\n\nMedia Manipulation\nFactually Correct\n\n\nMisleading\nNot Outdated\n\n\nNo Context\nOpinion\n\n\nNot Factual\nOther\n\n\nOutdated\nSatire\n\n\nSatire\n\n\n\nUnverified\n\n\n\n\n\n\nNote Ratings\nDesignated by Community Note program users, classifying whether the attached Community Note is Helpful, Somewhat Helpful or Not Helpful with subcategories for additional context. These are expressed as Boolean in the original data, but here counts are aggregated and expressed as proportions per Note (since the total number of ratings per Note can vary widely.)\n\n\n\n\n\n\n\nNote is Not Helpful\nNote is Helpful /\nNote is Somewhat Helpful\n\n\n\n\nArgumentative\nAddresses Issue\n\n\nBiased Opionion\nClear\n\n\nFactually Incorrect\nImportant Context\n\n\nHard to Understand\nShows Empathy\n\n\nMissing Information\nTrustworthy Sources\n\n\nOff Topic / Irrelevant\nUnbiased\n\n\nOutdated\n\n\n\nSpam\n\n\n\nSpeculation\n\n\n\nUntrustworthy Sources\n\n\n\n\n\n\n5.3 A Note on Algorithms\nWhile an analysis of the Community Note open-source algorithms are outside the scope of this study, a review of the documentation is suggested, especially as they pertain to some of the findings. (“Note Ranking Algorithm” 2025)\n\nData Sparsity: The main algorithm is essentially a sparse-matrix recommender, stemming from the low participation rates by Community Notes raters. The authors acknowledge “most raters do not rate most notes - and this sparsity leads to outliers and noise in the data.” Their solution is described as “higher regularization”, but the continued layering of additional models (Expanded Consensus, Net Helpful Minimums) suggests this problem remains challenging.\nScoring Instability: This data sparsity also contributes to instability of Community Note scores over time and is specifically addressed in the documentation: “…newer notes are able to receive more ratings from a wider range of contributors while the available ranking data for older notes remains more limited. As older data comprise an increasingly small fraction of the dataset, ranking results have tended to fluctuate, and some notes have lost Helpful status.”. Additional model layers (Scoring DriftCard) and “status locking” have been added to address this issue, but the data show this likely remains a problem.\nBinary Decision Spaces: One of the unique properties of the Community Note algorithms is to attempt “bridging” and building consensus among Raters with different political and social viewpoints, as represented by their individual rating histories. However, the documentation seems to acknowledge the computational difficulty at present of expanding into multidimensional viewpoint factors. “…for now, to avoid overfitting on our very small dataset, we only use 1-dimensional factors. We expect to increase this dimensionality as our dataset size grows significantly.”"
  },
  {
    "objectID": "papers/final/x-community-notes-effectiveness.html#experiment-design",
    "href": "papers/final/x-community-notes-effectiveness.html#experiment-design",
    "title": "Effectiveness and Systematic Constraints of Community Notes",
    "section": "6.1 Experiment Design",
    "text": "6.1 Experiment Design\nPrior work has suggested that the time-to-publication (TTP) of Community Notes interventions on X may be unacceptably long, blunting the potential impact of these interventions. This analysis will group CNs by their elapsed time between inception and publication and attempt to identify those characteristics associated with shorter and longer publish times. Possible factors may include post topics and subtopics, author account size and reach, post timing, post and reply content and sentiment, and measures of polarization / disagreement within the CN ratings data that may impact the algorithmically determined publish status.\n\nResearch Question 3: Are there procedural or systemic constraints impacting CN speed and effectiveness on a given platform?\nHypothesis: CN time-to-publication varies systematically by observable factors (e.g., topic, account influence, timing, polarization of CN rater agreement), implying procedural or systemic constraints.\nExperiment Design:\n\nANOVA Difference of Means, Linear, GLM or Robust Regression, Quantile Regression, Non-Parametric Models.\n\nTarget Variable: \\(T_{pub}=TS_{CNpub} - TS_{post}\\)\nPredictors: Community Note classifications, Community Note user ratings, Post engagement metrics and metadata, Post Author metadata, Custom Polarization metrics.\n\n\nConstraints: Several data-related limitations shaped the extent and types of analysis carried out in this study:\n\nAggregated Engagement Metrics in the Twitter Firehose API data make timeseries-based analysis such as Cascades (Vosoughi, Roy, and Aral 2018) difficult.\nLimited Access to the Twitter Firehose API due to increased costs restricted this study to datasets already obtained by other researchers.\nAdditional scraping of replies or user profiles may be challenging to perform at scale due to resource and processing constraints.\n\n\n\n6.1.1 Custom Metrics\nSeveral custom metrics are proposed to help quantify the aggregate CN ratings and levels of agreement/disagreement (polarization) between members of the CN ratings user base:\n\n\n\n\n\n\nMean Helpfulness Score\n\n\n\n\n\\[M  = \\frac{(1×H)+(0.5×S)+(−1×N)}{H+S+N}\\]\n\n\nApplied to the aggregated ratings on an individual Community Note, this metric indicates whether users found the CN helpful on average. A simple weighted average with numeric values assigned to each CN rating category:\n(H)elpful = +1.0\n(S)omewhat Helpful = +0.5\n(N)ot Helpful = -1.0\n\n\n\n\n\n\n\n\n\nPolarization Index - Standard (Ps)\n\n\n\n\n\\[P_S= \\frac{1}{2} \\sqrt{\\frac{(H⋅(1−ABS(M))^2)+(S⋅(0.5−ABS(M))^2)+(N⋅(−1−ABS(M))^2)}{H+S+N}}\\]\n\n\nAn index of opinion polarization of individual CNs based on the spread of their aggregated ratings. If ratings are all in one category, there’s no disagreement (low polarization). If ratings are evenly split between extremes, the polarization is high.\nNormally an index 0-1, but I halve the final result for an index from 0 (no polarization) to 0.5 (perfect polarization). More interpretable as “% of total population in disagreement”. Uses the Mean Helpfulness Score (M)."
  },
  {
    "objectID": "papers/final/x-community-notes-effectiveness.html#data-exploration",
    "href": "papers/final/x-community-notes-effectiveness.html#data-exploration",
    "title": "Effectiveness and Systematic Constraints of Community Notes",
    "section": "6.2 Data Exploration",
    "text": "6.2 Data Exploration\nInitial exploration of the two datasets revealed several major insights:\nCommunity Notes impact a very small percentage (~0.02%) of posts on the platform.\n\nOf 38.5M election-related posts in this dataset, only 5,551 (0.014%) received one or more notes.\nAlthough a current metric of misinformation on the platform is not readily available, this percentage seems rather low given the typical user experience and general prevalence of this content, especially during the 2024 election.\n\nOnly 4% of all submitted Community Notes have ever been published; 96% remain hidden from the general public.\n\nOf the 13,745 election-related notes, only 585 (4.3%) were ever published (classified Helpful) at some point. 12,238 (89%) were still classified “Need More Votes” (NMR) three months after the November 2024 election.\n\nThe median Community Note time-to-publish (TTP) is 8.7 hours, but with a great degree of variation (Mean 35.8 and SD 158.7)\n\n\nCode\ndf_notes_pub %&gt;%\n  mutate(ttp_hrs = nt_publish_min/60) %&gt;%\n  # filter(ttp_hrs &lt; 500) %&gt;%\n  ggplot(aes(x=ttp_hrs)) +\n  geom_histogram(bins=30, alpha=0.5, color='black') +\n  geom_vline(aes(xintercept = quantile(ttp_hrs, 0.25)), color='grey', linetype='dotted', size=1) +\n  geom_vline(aes(xintercept = quantile(ttp_hrs, 0.50)), color='green', linetype='dotted', size=1) +\n  geom_vline(aes(xintercept = quantile(ttp_hrs, 0.75)), color='grey', linetype='dotted', size=1) +\n  geom_vline(aes(xintercept = quantile(ttp_hrs, 0.82)), color='grey', linetype='dotted', size=1) +\n  annotate(\"text\", x = quantile(df_notes_pub$nt_publish_min/60, 0.50), y = 80, label = '50%', vjust = -0.5, hjust = -.25) +\n  annotate(\"text\", x = quantile(df_notes_pub$nt_publish_min/60, 0.83), y = 80, label = '83%', vjust = -0.5, hjust = -.25) +\n  scale_x_continuous(\n    trans = 'log1p',\n    labels = scales::label_number(),\n    breaks = c(1, 2, 4, 8, 12, 18, 24, 36, 48, 72, 100, 200, 500, 1000, 2000)\n  ) +\n  labs(title = \"Notes - Time-to-Publish Distribution (log)\", x = \"Hrs\", y = \"Count\") +\n  theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank()) \n\n\n\n\n\n\n\n\n\n\n83% of Community Notes that reach an initial Publish status do so within 24 hours.\nThe distribution of our response variable TTP is extremely right-skewed.\n\nCommunity Notes classifications can be unstable - over 36% of classified Notes have had their status changed, including 38% of all published notes.\n\nOf 1,507 election-related notes successfully classified as either “Helpful” or “Not Helpful”, 554 (36.8%) had their status changed back to NMR.\nOf the 585 notes ever published (“Helpful”), 224 (38%) later had their public status revoked.\nOnly 261 (2.6%) of all notes created remain published (“Helpful”).\n\nThe Community Notes program was essentially disabled for the entire month of August 2024.\n\nAfter a rapid increase in program activity in prior months, Community Notes submissions halted abruptly at the end of July 2024 and no notes were published until September 1, when activity suddenly resumed (though at reduced levels.)\n\n\n\nCode\ndf_notes_publish_dt &lt;- df_notes %&gt;% \n  mutate(nt_dt_created = as.Date(nt_ts_created)) %&gt;%\n  group_by(nt_dt_created) %&gt;%\n  summarize(note_count = n(), notes_published = sum(nt_publish)) %&gt;%\n  mutate(pct_publish = round(notes_published/note_count,2)) %&gt;%\n  arrange(nt_dt_created)\n\nscale = 0.0005\n\ndf_notes_publish_dt %&gt;%\n  mutate(date = as.Date(cut(as.Date(nt_dt_created), breaks = \"7 days\"))) %&gt;%\n  group_by(date) %&gt;%\n  summarize(note_count = sum(note_count), notes_published = sum(notes_published)) %&gt;%\n  mutate(pct_publish = notes_published / note_count) %&gt;%\n  ggplot(aes(x = date)) +\n  # Transparent red rectangle for August\n  annotate(\"rect\",\n           xmin = as.Date(\"2024-08-01\"),\n           xmax = as.Date(\"2024-08-31\"),\n           ymin = -Inf,\n           ymax = Inf,\n           alpha = 0.2,\n           fill = \"red\") +\n  geom_col(aes(y = note_count), fill = 'grey30', alpha = 0.5) +\n  geom_line(aes(y = pct_publish / scale), color = 'orange2', size = 0.5) +\n  scale_y_continuous(\n    name = \"Note Count\",\n    sec.axis = sec_axis(trans = ~ . * scale, name = \"Pct Publish\"))\n\n\n\n\n\n\n\n\n\nBlue (Premium) Users accounted for 75% of all Community Noted posts, despite being 12% of the overall user base.\n\nBlue users made up 75% of all authors with Community Noted posts (1,700 of 2,264 unique user ids.)\nBlue users make up only 11.6% of the total user accounts represented the raw posts data (439k of 4.2M user ids)\nWhile not analyzed further here, this appears to agree with research suggesting that Blue users were the primary drivers of misinformation on X during recent crises. (Brewster, Howard, and Schimmel 2023)"
  },
  {
    "objectID": "papers/final/x-community-notes-effectiveness.html#data-modeling-analysis",
    "href": "papers/final/x-community-notes-effectiveness.html#data-modeling-analysis",
    "title": "Effectiveness and Systematic Constraints of Community Notes",
    "section": "6.3 Data Modeling & Analysis",
    "text": "6.3 Data Modeling & Analysis\n\n6.3.1 Quantile Regression\nBoth Linear and Robust Regressions were initially fit with log-transformation on the response, normalization of the predictors and handling of multi-collinearity but the resulting models were unstable and failed to explain a significant proportion of the variance in the Time-to-Publish (TTP) response variable.\nAs noted above the relationships of the predictors to the TTP response are highly noisy, non-linear and include many extreme values that are difficult for linear models. However, since these outliers are part of the topic of interest and are arguably not drawn from a different distribution, approaches are required to deal with these conditions while retaining interpretability.\nQuantile Regression was selected instead to examine feature importance and marginal effects of the predictors at various quantiles of the TTP response variable, while handling the distribution skew and outliers more effectively. For this model the log-transformation was applied to the response, predictors were normalized, and multi-collinearity was handled by removing aliases and features with over 85% collinearity while retaining as much interpretability as possible.\n\n\nCode\n# prep data for modeling\ndf_mod &lt;- df_notes_pub %&gt;%\n  select(-all_of(c('nt_status_current','nt_status_changed', 'nt_publish_revoked', 'nt_publish_revoked_min'))) %&gt;%\n  mutate(twt_lang = as.factor(twt_lang))\n\n# inpute twt_views\nimp &lt;- mice(df_mod, maxit = 5, m = 5, print = FALSE, \n  predictorMatrix = {\n    pm &lt;- make.predictorMatrix(df_mod)\n    pm[,] &lt;- 0\n    pm[\"twt_views\", c(\"twt_replies\", \"twt_retweets\", \"twt_likes\", \"twt_quotes\",\"user_follower_ct\",\"user_friend_ct\")] &lt;- 1\n    pm\n  })\n\n# stripplot(imp, twt_views, pch = 19, xlab = \"Imputation number\")\ndf_mod_imp &lt;- complete(imp, action = 2)\n\n## multicolliearity\n\n# check for aliases (duplicate or linearly dependent columns)\ndf_alias &lt;- alias(lm(nt_publish_min ~ ., data = df_mod_imp))\n# remove 'nt_class_notmis_opinion','nr_rating_helpful_not','nr_mean_agg'\n\n# check for high correlations\nc_df_mod_imp &lt;- correlate(df_mod_imp)\n# c_df_mod_imp %&gt;% shave(upper=FALSE) %&gt;% rplot()\n\ncor_long &lt;- c_df_mod_imp %&gt;%\n  pivot_longer(cols = -term, names_to = \"variable\", values_to = \"correlation\") %&gt;%\n  filter(!is.na(correlation), abs(correlation) &gt;= 0.85) %&gt;%\n  filter(term != variable) %&gt;%\n  rowwise() %&gt;%\n  mutate(pair = paste(sort(c(term, variable)), collapse = \"_\")) %&gt;%\n  ungroup() %&gt;%\n  distinct(pair, .keep_all = TRUE) %&gt;%\n  select(term, variable, correlation)\n\n# cor_long\n# remove polar_std, polar_entropy, ratings_agg, nr_nothelpful_missing, nr_nothelpful_nnn\n\n# manual selection\ndf_mod_imp &lt;- df_mod_imp %&gt;%\n  select(-any_of(c('nt_class_notmis_opinion', 'nr_rating_helpful_not', 'nr_mean_agg', 'nr_polar_std', 'nr_polar_entropy', 'nr_ratings_agg', 'nr_nothelpful_missing', 'nr_nothelpful_nnn')))\n\n# quantile regression\nqr_recipe &lt;- \n  recipe(nt_publish_min ~ ., data = df_mod_imp) %&gt;%\n  step_log(all_outcomes()) %&gt;%\n  step_normalize(all_numeric_predictors()) %&gt;%\n  step_dummy(twt_lang)\n\n# df for qr\ndf_qr_prep &lt;- prep(qr_recipe, training = df_mod_imp) %&gt;% bake(new_data=NULL)\n\n# fit qr on quartiles\nqr_mod1 &lt;- rq(nt_publish_min ~ ., tau = c(0.25, 0.5, 0.75, 1.0), data = df_qr_prep)\n\n# bootstrap SEs\nqr_results &lt;- summary(qr_mod1, se = \"boot\", R = 1000)\n\n# function to back-transform based on log response\nfunc_qr_back &lt;- function(df){\n  df %&gt;%\n    rownames_to_column() %&gt;%\n    mutate(`Std. Error` = exp(Value) * `Std. Error`, # goes first\n            Value = ifelse(rowname == '(Intercept)', -exp(Value), exp(Value)-1), \n            `t value` = Value / `Std. Error`, \n            ci_lo = Value - 1.96 * `Std. Error`, \n            ci_hi = Value + 1.96 * `Std. Error`)}\n\n# back-transform and join tables\ndf_qr_q25 &lt;- as.data.frame(qr_results[[1]]$coefficients) %&gt;%\n  func_qr_back %&gt;%\n  rename(val_25 = 2, se_25 = 3, t_25 = 4, p_25 = 5, ci_lo_25 = 6, ci_hi_25 = 7)\n  \ndf_qr_q50 &lt;- as.data.frame(qr_results[[2]]$coefficients) %&gt;% \n  func_qr_back %&gt;%\n  rename(val_50 = 2, se_50 = 3, t_50 = 4, p_50 = 5, ci_lo_50 = 6, ci_hi_50 = 7)\n\ndf_qr_q75 &lt;- as.data.frame(qr_results[[3]]$coefficients) %&gt;% \n  func_qr_back %&gt;%\n  rename(val_75 = 2, se_75 = 3, t_75 = 4, p_75 = 5, ci_lo_75 = 6, ci_hi_75 = 7)\n\ndf_qr_q100 &lt;- as.data.frame(qr_results[[4]]$coefficients) %&gt;% \n  func_qr_back %&gt;%\n  rename(val_100 = 2, se_100 = 3, t_100 = 4, p_100 = 5, ci_lo_100 = 6, ci_hi_100 = 7)\n\ndf_qr_results &lt;- \n  Reduce(function(x, y) left_join(x, y, by = 'rowname'), list(df_qr_q25, df_qr_q50, df_qr_q75, df_qr_q100)) %&gt;%\n  mutate(sum_p = rowSums(select(., starts_with(\"p_\")))) %&gt;%\n  left_join(df_nicenames)\n\n# graphs\n\n# function for qr graphs\nfunc_qr_graphs &lt;- function(df, var) {\n  df_var &lt;- df %&gt;% filter(rowname == var)\n  nicename &lt;- unique(df_var$nicename)\n\n  df_var %&gt;%\n    select(any_of(starts_with(c('val_','ci_','p_')))) %&gt;%\n    pivot_longer(cols = everything(),\n                 names_to = c(\".value\", \"quantile\"),\n                 names_pattern = \"(.*)_(\\\\d+)\") %&gt;%\n    mutate(\n      quantile = as.numeric(quantile),\n      color = case_when(p &lt;= 0.05 ~ \"green\",\n                        p &gt; 0.05 & p &lt;= 0.10 ~ \"yellow\",\n                        p &gt; 0.10 & p &lt;= 0.20 ~ \"orange\",\n                        TRUE ~ \"red\")) %&gt;%\n    ggplot(aes(x = quantile, y = val)) +\n      geom_line() +\n      geom_ribbon(aes(ymin = ci_lo, ymax = ci_hi), alpha = 0.2) +\n      geom_point(aes(color = color), size = 3) +\n      geom_text(aes(label = paste0(round(val * 100, 0), \"%\")), vjust = -1.2, size = 3) +\n      geom_hline(yintercept = 0, linetype = \"dashed\") +\n      scale_color_identity() +\n      scale_x_continuous(breaks = c(25, 50, 75, 100)) +\n      labs(x = \"Quantile\", y = \"Value\", title = nicename)\n    }\n\n\n\nModel Coefficients\nThe resulting coefficients were back-transformed to original scale and may be interpreted as having a multiplicative relationship with the response variable, Time to Publish (TTP), holding all other variables constant.\nFor example, a +10% point estimate for a given variable and quantile indicates that for a 1-unit increase in the variable (whether a proportion, a count, or a True condition for a Boolean) we may expect a 10% marginal increase in TTP, holding all other variables constant.\nLikewise, a -10% point estimate indicates a 1-unit increase in the variable would be associated with a 10% marginal decrease in TTP, holding all other variables constant.\n\n\n\n\n\n\n\nQuartiles and TTP\nSignificance Levels\n\n\n\n\nTTP distribution is extremely right-skewed. Median TTP is 8.7 hours (Mean 35.8, SD 159)\nIndividual estimates at all levels of significance are included in the graphs, but should be considered accordingly:\n\n\n\nFirst Quartile (p25): &lt;= 4.7 hrs\nSecond Quartile (p50): &lt;= 8.7 hrs\nThird Quartile (p75): &lt;= 18 hrs\nFourth Quartile (p100): &gt; 18 hrs\n\n\nGreen for p &lt;= 0.05 (high significance)\nYellow for p &gt; 0.05 and &lt;= 0.10 (moderate high)\nOrange for p &gt; 0.10 and &lt;= 0.20 (moderate low)\nRed for p &gt; 0.20 (low significance)\n\n\n\n\n\n\nPost Classification\nPost Classifications are assigned by the Community Note authors, categorizing the attached posts as Misinfo or Not Misinfo, along with related subcategories. These are expressed as Booleans.\n\n\nCode\n# note classification\ntop_qr_rows &lt;- df_qr_results %&gt;%\n  filter(str_starts(rowname, \"nt_\")) %&gt;%\n  arrange(sum_p) %&gt;%\n  slice_head(n = 12) %&gt;%\n  pull(rowname)\n\nplots &lt;- lapply(top_qr_rows, function(row) func_qr_graphs(df_qr_results, row))\nwrap_plots(plots, ncol = 3, heights=5) \n\n\n\n\n\n\n\n\n\nShorter TTP\n\nIs Media Note: Notes that address specific media attached to a Post (images, videos) rather than the Post content itself seem to have a consistent and significant association with shorter TTP. In fact, this effect increases at higher quartiles, suggesting this format may be beneficial for Notes that may otherwise be delayed by other factors.\nMisinfo: Posts broadly categorized as Misinfo or Misleading are consistently associated with dramatically shorter TTP (-50%+), though most of these estimates have low significance. This effect is the highest and most significant in the top quartile.\n\nLonger TTP\n\nMisinfo - Not Factual: Posts categorized as Misinfo - Not Factual are consistently associated with longer TTP, most significantly in the first quartile (+35%) and last quartile (+89%). This seems at odds with the broader parent classification Misinfo and could indicate dynamics such as greater disagreement between high-scoring raters over factual correctness, or simply a lower degree of rater engagement on this particular subtopic.\nMisinfo - Media Manipulation: Posts categorized as containing manipulated media (deepfakes, doctored footage) had a strong and moderately significant effect in the first quartile (+36), with decreasing effects for greater quartiles. Whether this is due to greater disagreement or lower rater engagement with the subtopic, the effect seems to largely impact Notes published within the first 24 hours.\n\n\n\nNote Ratings\nNote Ratings are assigned by users that participate in the Community Notes program. Expressed as proportions of total ratings per Note.\n\n\nCode\n# note ratings\ntop_qr_rows &lt;- df_qr_results %&gt;%\n  filter(str_starts(rowname, \"nr_\")) %&gt;%\n  arrange(sum_p) %&gt;%\n  slice_head(n = 12) %&gt;%\n  pull(rowname)\n\nplots &lt;- lapply(top_qr_rows, function(row) func_qr_graphs(df_qr_results, row))\nwrap_plots(plots, ncol = 3, heights=5) \n\n\n\n\n\n\n\n\n\nShorter TTP\n\nRatings Count: Similar to Is Media Note, this factor seems consistently effective and significant across all quartiles, outlining that increased Rater interest and participation in the process helps reduce TTP for any given Note.\nNot Helpful - Incorrect: Notes that are rated Not Helpful due to factual errors are associated with shorter TTP, with the effect increasing at higher quartiles.\n\nThis is one of the more counter-intuitive findings of the model, in which rater agreement on lower-quality notes is associated with shorter TTP, not longer.\n\nHelpful - Some and Helpful - Addresses Issue: Both ratings are associated with decreases in TTP, with effects and significance generally increasing at higher quartiles.\n\nLonger TTP\n\nHelpful - Source Reliable: Notes rated as drawing on reliable sources are associated with longer TTP, increasing over greater quartiles with a large and highly significant effect (+170%) in the last quartile.\n\nThis is another counter-intuitive finding in which rater agreement on higher-quality notes is associated with longer TTP, not shorter.\n\nNot Helpful - Opinion: Notes rated as Opinion are associated with longer TTP, though at low significance levels.\n\n\n\nPost Language\nPost Language is expressed as a Boolean.\n\n\nCode\n# post language\ntop_qr_rows &lt;- df_qr_results %&gt;%\n  filter(str_starts(rowname, \"twt_lang\")) %&gt;%\n  arrange(sum_p) %&gt;%\n  slice_head(n = 12) %&gt;%\n  pull(rowname)\n\nplots &lt;- lapply(top_qr_rows, function(row) func_qr_graphs(df_qr_results, row))\nwrap_plots(plots, ncol = 3, heights=5) \n\n\n\n\n\n\n\n\n\n\nPost Language: While significance levels were variable, nearly all Language classifications shared similar effects with increasing TTP and uncertainty towards higher quartiles. However Polish-language posts are the exception with decreasing TTP and stronger significance toward higher quartiles.\n\nOne possible hypothesis could be the presence of a relatively active community of Polish-language raters and/or better participation levels due to a relatively smaller proportion of Polish-language tweets.\n\n\n\n\nPost Engagement\nPost Engagement effects tend to be on a smaller scale since they are based on counts rather than categoricals or overall proportions.\n\n\nCode\n# post engagement\ntop_qr_rows &lt;- df_qr_results %&gt;%\n  filter(str_starts(rowname, \"twt_\")) %&gt;%\n  filter(!str_starts(rowname, \"twt_lang\")) %&gt;%\n  arrange(sum_p) %&gt;%\n  slice_head(n = 12) %&gt;%\n  pull(rowname)\n\nplots &lt;- lapply(top_qr_rows, function(row) func_qr_graphs(df_qr_results, row))\nwrap_plots(plots, ncol = 3, heights=5) \n\n\n\n\n\n\n\n\n\nLonger TTP in Lower Quartiles\n\nPost Replies, Views, Retweets and Posts that are Quotes are associated with slightly longer TTP in the early quartiles, and shorter TTP in the later quartiles.\n\nAt first this relationship seems counter-intuitive; one might expect Posts with high levels of engagement to also have higher levels of Rater activity. However. for higher quartiles, more time has elapsed, and more Post engagement has likely accrued.\n\n\nShorter TTP in Lower Quartiles\n\nPost Likes have the opposite effect of the other engagement metrics, associated with shorter TTP in the early quartiles, and longer TTP in the later quartiles.\n\nOne possible explanation for the disparity is that Likes may be a more direct signal of user agreement than Replies, Views or even Retweets, and that the relative popularity of Posts in the earlier quartiles may correlate to increased Rater activity.\nThis could also be an effect of a recommendation algorithm that prompts Raters to respond to Notes; Likes may be one of many signals that trigger the prompt.\n\n\n\n\nPost Author\nPost Author metrics are expressed as counts except for Author:Blue, which is expressed as a Boolean.\n\n\nCode\n# post author\ntop_qr_rows &lt;- df_qr_results %&gt;%\n  filter(str_starts(rowname, \"user_\")) %&gt;%\n  arrange(sum_p) %&gt;%\n  slice_head(n = 12) %&gt;%\n  pull(rowname)\n\nplots &lt;- lapply(top_qr_rows, function(row) func_qr_graphs(df_qr_results, row))\nwrap_plots(plots, ncol = 3, heights=5) \n\n\n\n\n\n\n\n\n\nShorter TTP\n\nAuthor - Blue: Posts from premium “Blue” accounts were associated with significantly shorter TTP in the early quartiles. While this could be an effect of Blue posts receiving preferential, more frequent placement in user feeds, we might consider whether this supports research into Blue accounts driving a larger share of overall misinformation on the platform. (Brewster, Howard, and Schimmel 2023)\nFriend Count and Follower Count: Both variables are associated with 5-10% shorter TTP in the first three quartiles, possibly correlated to Posts with larger followings and reach.\n\n\n\n\n6.3.2 Random Forest\nIn addition to Quantile regression, I fit a random forest model to identify key features affecting Community Note time-to-publication. Using the ranger package with 1000 trees and impurity-based variable importance, the model achieved a fairly low \\(R^2\\) of 0.15, confirming the dataset contains substantial variability that cannot be explained by the Post, Note and User variables alone.\nDespite the weakness of the model, the feature importance rankings agreed in many instances with the Quantile regression, confirming the strong effects of Rating counts and Note Helpful classifications, while seeming to emphasize User Account and Post Engagement metrics more heavily.\n\n\nCode\n# random forest\nrf_recipe &lt;- \n  recipe(nt_publish_min ~ ., data = df_mod) %&gt;%\n  step_log(all_outcomes())\n\ndf_rf_prep &lt;- prep(rf_recipe, training = df_mod) %&gt;% bake(new_data=NULL)\n\n# fit model\nrf_fit &lt;- rand_forest(mode='regression', trees=1000) %&gt;%\n  set_engine('ranger', importance='impurity') %&gt;%\n  fit(nt_publish_min ~ ., df_rf_prep)\n\nrf_fit\n\n\nparsnip model object\n\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.trees = ~1000,      importance = ~\"impurity\", num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1)) \n\nType:                             Regression \nNumber of trees:                  1000 \nSample size:                      552 \nNumber of independent variables:  49 \nMtry:                             7 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       1.200379 \nR squared (OOB):                  0.1544627 \n\n\nCode\n# variable importance\nrf_varimp &lt;- data.frame(\n  variable = names(rf_fit$fit$variable.importance),\n  importance = round(rf_fit$fit$variable.importance,3)) %&gt;%\n  arrange(desc(importance))\n\nggplot(rf_varimp[1:10,], aes(x = reorder(variable, importance), y = importance)) +\n  geom_col(fill='blue', alpha = 0.7) +\n  coord_flip() +\n  labs(title = \"RF - Top 10 Variable Importances\", x = NULL, y = \"Importance\")"
  },
  {
    "objectID": "papers/final/x-community-notes-effectiveness.html#findings-and-discussion",
    "href": "papers/final/x-community-notes-effectiveness.html#findings-and-discussion",
    "title": "Effectiveness and Systematic Constraints of Community Notes",
    "section": "6.4 Findings and Discussion",
    "text": "6.4 Findings and Discussion\nThis data offers some support for the hypothesis that X Community Notes time-to-publication varies systematically based on observable factors. This analysis also outlines possible systemic constraints that affect its overall effectiveness as community-driven misinformation intervention tool, supporting other research and the program’s own acknowledgments of technical and computational challenges.\nKey Coverage and Performance Metrics (2024 U.S. Presidential Election)\n\nCommunity Notes impacted only 0.014% of election-related posts. (5,551 out of 38.5M)\nOnly 4% of submitted Notes (585 of 13,745) ever reached publication status.\nMedian publication time was 8.7 hours, but with extreme variation. (Mean 35.8, SD 158.7.)\nStatus instability affected 36% of classified notes, with 38% of published notes later having their public status revoked.\nProgram activity halted entirely during August 2024, a critical pre-election period.\nBlue (Premium) users were disproportionately represented, accounting for 75% of noted posts despite being only 12% of the user base.\n\nSystematic Factors Affecting Publication Speed\nQuantile regression revealed several statistically significant factors affecting TTP:\nShorter TTP:\n\nMedia-focused notes (addressing images/videos)\nNotes classified misinformation (up to 50% reduction in TTP)\nHigher rating counts (more rater participation)\nNotes classified as Not Helpful - Incorrect\nAccounts with higher follower and friend counts\n\nLonger TTP:\n\nSpecifically categorized “Not Factual” content (+35% to +89%)\nPosts with manipulated media (+36% in first quartile)\nCounter-intuitively, notes rated as having reliable sources (+170% in last quartile)\n\nTechnical and Operational Challenges\nThe platform’s documentation acknowledges several issues these findings appear to support:\n\nData sparsity (“most raters do not rate most notes”)\nScoring instability (notes losing “Helpful” status over time)\nComputational limitations in the consensus algorithms\nInsufficient rater participation as a primary bottleneck\n\nImplications\nWhen evaluated against X’s own stated objectives for Community Notes, these findings indicate:\n\nThe program struggles with systematic biases affecting which notes receive ratings and which topics reach consensus.\nWhile technically open-source, unexplained operational disruptions undermine transparency.\nThe extremely limited coverage (0.014% of posts) and low publication rate (4% of notes) suggest the program falls far short of providing effective intervention at scale.\n\nThis minimal coverage suggests that users and brands remained exposed to potential misinformation with little protection from the Community Notes program during the 2024 U.S. Presidential Election.\nWhile conceptually promising, the program in its current state appears inadequate to address the scale and complexity of misinformation, particularly during critical periods like elections. The systematic variations in publication speed and extremely low coverage rate suggest fundamental limitations that would need to be addressed for the program to serve as an effective intervention tool.\nFuture Research Directions\n\nAnalysis of Community Notes user base quality scores and participation rates on publish outcomes.\nQualitative assessment of the 96% of unpublished notes.\nMeasurement of intervention effects on user sentiment, behavior and networks.\nSimulation testing with the open-source CN algorithms to identify bottlenecks.\nExpansion of analyses to other misinformation-heavy topic areas (medical, finance, public emergencies, etc.)"
  },
  {
    "objectID": "papers/final/x-community-notes-effectiveness.html#code-and-data",
    "href": "papers/final/x-community-notes-effectiveness.html#code-and-data",
    "title": "Effectiveness and Systematic Constraints of Community Notes",
    "section": "6.5 Code and Data",
    "text": "6.5 Code and Data\n\nThis paper and all code used for data processing and analysis may be found at https://github.com/jefedigital/social-cdi-effectiveness.\nThe original USC X 24 US election X Dataset is hosted at https://github.com/sinking8/usc-x-24-us-election.\nAll X Community Notes datasets are publicly available at https://x.com/i/communitynotes/download-data."
  },
  {
    "objectID": "papers/final/x-community-notes-effectiveness.html#data-dictionary-analysis.notes_ttp",
    "href": "papers/final/x-community-notes-effectiveness.html#data-dictionary-analysis.notes_ttp",
    "title": "Effectiveness and Systematic Constraints of Community Notes",
    "section": "9.1 Data Dictionary: analysis.notes_ttp",
    "text": "9.1 Data Dictionary: analysis.notes_ttp\n\n\n\n\n\n\n\n\n\nColumn\nDescription\nColumn\nDescription\n\n\n\n\nnt_id\nUnique Note ID\nnr_helpful_sources\nNote Ratings - Helpful - Trustworthy Sources\n\n\nnt_author_id\nUnique Note Author ID\nnr_helpful_ctxt_unique\nNote Ratings - Helpful - Unique Context\n\n\nnt_ts_created\nNote Created (datetime)\nnr_helpful_address\nNote Ratings - Helpful - Addresses Issue\n\n\nnt_is_medianote\nIs Media Note (bool)\nnr_helpful_ctxt_impt\nNote Ratings - Helpful - Important Context\n\n\nnt_created_min\nMinutes between Tweet Created and Note Created\nnr_helpful_unbiased\nNote Ratings - Helpful - Unbiased\n\n\nnt_status_current\nNote Current Status (NMR, Published)\nnr_nothelpful_other\nNote Ratings - Not Helpful - Other\n\n\nnt_status_changed\nDid Note Status ever change (bool)\nnr_nothelpful_incorrect\nNote Ratings - Not Helpful -Incorrect\n\n\nnt_publish\nWas Note ever published (bool)\nnr_nothelpful_source\nNote Ratings - Not Helpful - Untrustworthy Source\n\n\nnt_publish_min\nMinutes between Note Created and Note Published\nnr_nothelpful_opinion_bias\nNote Ratings - Not Helpful - Biased Opinion\n\n\nnt_publish_revoked\nWas Note Publish ever revoked (bool)\nnr_nothelpful_missing\nNote Ratings - Not Helpful - Missing Information\n\n\nnt_publish_revoked_min\nMinutes between Note Published at Note Publish Revoked\nnr_nothelpful_outdated\nNote Ratings - Not Helpful - Outdated\n\n\nnt_class_misinfo\nNote classified Misinfo (bool)\nnr_nothelpful_understand\nNote Ratings - Not Helpful - Hard to Understand\n\n\nnt_class_trustsource\nTweet classified Trustworthy Source (bool)\nnr_nothelpful_argument\nNote Ratings - Not Helpful - Argumentative\n\n\nnt_class_mis_misleading\nTweet classified Misinfo - Misleading\nnr_nothelpful_offtopic\nNote Ratings - Not Helpful - Off Topic\n\n\nnt_class_mis_notfactual\nTweet classified Misinfo - Not Factual\nnr_nothelpful_spam\nNote Ratings - Not Helpful - Spam\n\n\nnt_class_mis_mediamanip\nTweet classified Misinfo - Media Manipulation\nnr_nothelpful_source_irrev\nNote Ratings - Not Helpful - Irrelevant\n\n\nnt_class_mis_outdated\nTweet classified Misinfo - Outdated\nnr_nothelpful_opinion_spec\nNote Ratings - Not Helpful - Opinion, Speculation\n\n\nnt_class_mis_nocontext\nTweet classified Misinfo - No Context\nnr_nothelpful_nnn\nNote Ratings - Not Helpful - No Note Needed\n\n\nnt_class_mis_unverified\nTweet classified Misinfo - Unverified\ntwt_id\nUnique Tweet ID\n\n\nnt_class_mis_satire\nTweet classified Misinfo - Satire\ntwt_url\nUnique Tweet URL\n\n\nnt_class_notmis_other\nTweet classified Not Misinfo - Other\ntwt_author_id\nUnique Tweet Author ID\n\n\nnt_class_notmis_correct\nTweet classified Not Misinfo - Factually Correct\ntwt_reply_author_id\nUnique Reply-to Tweet Author ID\n\n\nnt_class_notmis_notoutdated\nTweet classified Not Misinfo - Not Outdated\ntwt_convo_id\nConversaion (Original Tweet) ID\n\n\nnt_class_notmis_satire\nTweet classified Not Misinfo - Satire\ntwt_lang\nTweet Language Code\n\n\nnt_class_notmis_opinion\nTweet classified Not Misinfo - Opinion\ntwt_views\nTweet Views Count\n\n\nnr_ratings_ct\nNote Ratings - Count of total Ratings\ntwt_replies\nTweet Replies Count\n\n\nnr_rating_helpful\nNote Ratings - Helpful (1.0)\ntwt_retweets\nTweet Retweets Count\n\n\nnr_rating_helpful_somewhat\nNote Ratings - Somewhat Helpful (0.5)\ntwt_likes\nTweet Likes Count\n\n\nnr_rating_helpful_not\nNote Ratings - Not Helpful (-1.0)\ntwt_quotes\nTweet Quotes Count\n\n\nnr_ratings_agg\nNote Ratings - Weighted Sum - Custom Metric\ntwt_is_retweet\nTweet is a Retweet (bool)\n\n\nnr_mean_agg\nNote Ratings - Mean of Weighted Sum - Custom Metric (-1 to +1)\ntwt_is_quote\nTweet is a Quote (bool)\n\n\nnr_polar_std\nNote Ratings - Polarization (Standard) - Custom Metric (0 to 0.5)\nuser_follower_ct\nTweet Author Follower Count\n\n\nnr_polar_entropy\nNote Ratings - Polarization (Entropy) - Custom Metric (0 to ~1.6)\nuser_friend_ct\nTweet Author Friend Count\n\n\nnr_helpful_other\nNote Ratings - Helpful - Other\nuser_blue\nTweet Author is Blue (Premium Account)\n\n\nnr_helpful_clear\nNote Ratings - Helpful - Clear\nuser_created_dt\nTweet Author Account Creation Date\n\n\nnr_helpful_empathy\nNote Ratings - Helpful - Empathy\nuser_account_age\nTweet Author Account Age (days)"
  }
]